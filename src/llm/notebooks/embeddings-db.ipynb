{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f97178c-58d0-443f-b043-f4230c2a524b",
   "metadata": {},
   "source": [
    "# Vector Database Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2ad1ff-fed6-4a60-92e2-40a83c43b5b5",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c286ad94-6e17-4c33-a111-a14e49b24227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.11/site-packages (4.12.2)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (2.31.0)\n",
      "Requirement already satisfied: pandas in /opt/conda/lib/python3.11/site-packages (2.0.3)\n",
      "Collecting langchain\n",
      "  Downloading langchain-0.0.221-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m0m\n",
      "\u001b[?25hCollecting tiktoken\n",
      "  Downloading tiktoken-0.4.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: pyarrow in /opt/conda/lib/python3.11/site-packages (12.0.1)\n",
      "Collecting fastparquet\n",
      "  Downloading fastparquet-2023.7.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting chromadb\n",
      "  Downloading chromadb-0.3.26-py3-none-any.whl (123 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.6/123.6 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.11/site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests) (2023.5.7)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: numpy>=1.21.0 in /opt/conda/lib/python3.11/site-packages (from pandas) (1.24.4)\n",
      "Requirement already satisfied: PyYAML>=5.4.1 in /opt/conda/lib/python3.11/site-packages (from langchain) (6.0)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.0.17)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.8.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting dataclasses-json<0.6.0,>=0.5.7 (from langchain)\n",
      "  Downloading dataclasses_json-0.5.9-py3-none-any.whl (26 kB)\n",
      "Collecting langchainplus-sdk>=0.0.17 (from langchain)\n",
      "  Downloading langchainplus_sdk-0.0.19-py3-none-any.whl (25 kB)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.8.4)\n",
      "Collecting openapi-schema-pydantic<2.0,>=1.2 (from langchain)\n",
      "  Downloading openapi_schema_pydantic-1.2.4-py3-none-any.whl (90 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.0/90.0 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting pydantic<2,>=1 (from langchain)\n",
      "  Downloading pydantic-1.10.10-py3-none-any.whl (158 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m158.1/158.1 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tenacity<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.2.2-py3-none-any.whl (24 kB)\n",
      "Collecting regex>=2022.1.18 (from tiktoken)\n",
      "  Downloading regex-2023.6.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (781 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.1/781.1 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting cramjam>=2.3 (from fastparquet)\n",
      "  Downloading cramjam-2.6.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from fastparquet) (2023.6.0)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.11/site-packages (from fastparquet) (23.1)\n",
      "Collecting hnswlib>=0.7 (from chromadb)\n",
      "  Downloading hnswlib-0.7.0.tar.gz (33 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting clickhouse-connect>=0.5.7 (from chromadb)\n",
      "  Downloading clickhouse_connect-0.6.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting duckdb>=0.7.1 (from chromadb)\n",
      "  Downloading duckdb-0.8.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (14.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/14.8 MB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting fastapi>=0.85.1 (from chromadb)\n",
      "  Downloading fastapi-0.99.1-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting uvicorn[standard]>=0.18.3 (from chromadb)\n",
      "  Downloading uvicorn-0.22.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting posthog>=2.4.0 (from chromadb)\n",
      "  Downloading posthog-3.0.1-py2.py3-none-any.whl (37 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.5.0 in /opt/conda/lib/python3.11/site-packages (from chromadb) (4.7.0)\n",
      "Collecting pulsar-client>=3.1.0 (from chromadb)\n",
      "  Downloading pulsar_client-3.2.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting onnxruntime>=1.14.1 (from chromadb)\n",
      "  Downloading onnxruntime-1.15.1-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tokenizers>=0.13.2 (from chromadb)\n",
      "  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (7.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m16.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.65.0 in /opt/conda/lib/python3.11/site-packages (from chromadb) (4.65.0)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.11/site-packages (from chromadb) (7.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.4-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (120 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m120.1/120.1 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.2-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (278 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.2/278.2 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.3.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (153 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.3/153.3 kB\u001b[0m \u001b[31m18.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Requirement already satisfied: zstandard in /opt/conda/lib/python3.11/site-packages (from clickhouse-connect>=0.5.7->chromadb) (0.19.0)\n",
      "Requirement already satisfied: lz4 in /opt/conda/lib/python3.11/site-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
      "Collecting marshmallow<4.0.0,>=3.3.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
      "  Downloading marshmallow-3.19.0-py3-none-any.whl (49 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.1/49.1 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting marshmallow-enum<2.0.0,>=1.5.1 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
      "  Downloading marshmallow_enum-1.5.1-py2.py3-none-any.whl (4.2 kB)\n",
      "Collecting typing-inspect>=0.4.0 (from dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting starlette<0.28.0,>=0.27.0 (from fastapi>=0.85.1->chromadb)\n",
      "  Downloading starlette-0.27.0-py3-none-any.whl (66 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.0/67.0 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting coloredlogs (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers (from onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (4.23.2)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (1.12)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Collecting monotonic>=1.5 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading monotonic-1.6-py2.py3-none-any.whl (8.2 kB)\n",
      "Collecting backoff>=1.10.0 (from posthog>=2.4.0->chromadb)\n",
      "  Downloading backoff-2.2.1-py3-none-any.whl (15 kB)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
      "Collecting h11>=0.8 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting httptools>=0.5.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading httptools-0.5.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (395 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m395.5/395.5 kB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting python-dotenv>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading python_dotenv-1.0.0-py3-none-any.whl (19 kB)\n",
      "Collecting uvloop!=0.15.0,!=0.15.1,>=0.14.0 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading uvloop-0.17.0-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (4.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/4.2 MB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting watchfiles>=0.13 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading watchfiles-0.19.0-cp37-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (1.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting websockets>=10.4 (from uvicorn[standard]>=0.18.3->chromadb)\n",
      "  Downloading websockets-11.0.3-cp311-cp311-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (131 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m131.2/131.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.11/site-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (3.7.0)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime>=1.14.1->chromadb)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->onnxruntime>=1.14.1->chromadb) (1.3.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (1.3.0)\n",
      "Building wheels for collected packages: hnswlib\n",
      "  Building wheel for hnswlib (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hnswlib: filename=hnswlib-0.7.0-cp311-cp311-linux_aarch64.whl size=174411 sha256=d6dae0ec6fa45fa5f7e30c61359eb8c9ee4e6b2d0817198b4195bb12906f47d8\n",
      "  Stored in directory: /home/jovyan/.cache/pip/wheels/fd/ea/08/149cab5879745530dcf6e264a61e0cc54a4e2e291247bb99ab\n",
      "Successfully built hnswlib\n",
      "Installing collected packages: tokenizers, monotonic, flatbuffers, duckdb, websockets, uvloop, tenacity, regex, python-dotenv, pydantic, pulsar-client, mypy-extensions, multidict, marshmallow, humanfriendly, httptools, hnswlib, h11, frozenlist, cramjam, clickhouse-connect, backoff, async-timeout, yarl, watchfiles, uvicorn, typing-inspect, tiktoken, starlette, posthog, openapi-schema-pydantic, marshmallow-enum, langchainplus-sdk, coloredlogs, aiosignal, onnxruntime, fastparquet, fastapi, dataclasses-json, aiohttp, langchain, chromadb\n",
      "Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 backoff-2.2.1 chromadb-0.3.26 clickhouse-connect-0.6.4 coloredlogs-15.0.1 cramjam-2.6.2 dataclasses-json-0.5.9 duckdb-0.8.1 fastapi-0.99.1 fastparquet-2023.7.0 flatbuffers-23.5.26 frozenlist-1.3.3 h11-0.14.0 hnswlib-0.7.0 httptools-0.5.0 humanfriendly-10.0 langchain-0.0.221 langchainplus-sdk-0.0.19 marshmallow-3.19.0 marshmallow-enum-1.5.1 monotonic-1.6 multidict-6.0.4 mypy-extensions-1.0.0 onnxruntime-1.15.1 openapi-schema-pydantic-1.2.4 posthog-3.0.1 pulsar-client-3.2.0 pydantic-1.10.10 python-dotenv-1.0.0 regex-2023.6.3 starlette-0.27.0 tenacity-8.2.2 tiktoken-0.4.0 tokenizers-0.13.3 typing-inspect-0.9.0 uvicorn-0.22.0 uvloop-0.17.0 watchfiles-0.19.0 websockets-11.0.3 yarl-1.9.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install beautifulsoup4 requests pandas langchain tiktoken pyarrow fastparquet chromadb --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f8fe43-4564-4af0-806c-5ba884003511",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d8cc8ea-3595-4324-809b-3aa3ce779618",
   "metadata": {},
   "source": [
    "### Documents URL Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5fd454a-7e5c-4a3f-97ae-fe5c3f04e122",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://airflow.apache.org/docs/apache-airflow/stable/public-airflow-interface.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/deprecated-rest-api-ref.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/migrations-ref.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/cli-and-env-variables-ref.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/release_notes.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/administration-and-deployment/index.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/stable-rest-api-ref.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/ui.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/configurations-ref.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/howto/index.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/authoring-and-scheduling/index.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/extra-packages-ref.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/privacy_notice.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/templates-ref.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/database-erd-ref.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/faq.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/project.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/core-concepts/index.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/operators-and-hooks-ref.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/start.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/integration.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/release-process.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/security/index.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/tutorial/index.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/license.html\n",
      "https://airflow.apache.org/docs/apache-airflow/stable/installation/index.html\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from urllib.parse import urlparse\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "root_url = \"https://airflow.apache.org/docs/apache-airflow/stable/\"\n",
    "root_response = requests.get(root_url)\n",
    "root_html = root_response.content.decode(\"utf-8\")\n",
    "soup = BeautifulSoup(root_html, 'html.parser')\n",
    "\n",
    "root_url_parts = urlparse(root_url)\n",
    "root_links = soup.find_all(\"a\", attrs={\"class\": \"reference internal\"})\n",
    "\n",
    "result = set()\n",
    "for root_link in root_links:\n",
    "    path = root_url_parts.path + root_link.get(\"href\")\n",
    "    path = str(Path(path).resolve())\n",
    "    path = urlparse(path).path\n",
    "    url = f\"{root_url_parts.scheme}://{root_url_parts.netloc}{path}\"\n",
    "    result.add(url)\n",
    "urls = list(result)\n",
    "print(*urls, sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c302bf0-b2a0-44a2-b395-06b7d73b8291",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total documents:  1474\n"
     ]
    }
   ],
   "source": [
    "from langchain.document_loaders import WebBaseLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "\n",
    "loader = WebBaseLoader(urls)\n",
    "documents = loader.load()\n",
    "\n",
    "# Select one of the following:\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
    "# text_splitter = CharacterTextSplitter.from_tiktoken_encoder(chunk_size=1000, chunk_overlap=100)\n",
    "\n",
    "splitted_documents = text_splitter.split_documents(documents)\n",
    "print(\"Total documents: \", len(splitted_documents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5077025e-c22b-4606-aeed-46ef66cb9e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_content</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Public Interface of Airflow — Airflow Document...</td>\n",
       "      <td>https://airflow.apache.org/docs/apache-airflow...</td>\n",
       "      <td>Public Interface of Airflow — Airflow Document...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Announcements\\n                            \\n\\...</td>\n",
       "      <td>https://airflow.apache.org/docs/apache-airflow...</td>\n",
       "      <td>Public Interface of Airflow — Airflow Document...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Task Instance Keys\\nairflow.models.taskinstanc...</td>\n",
       "      <td>https://airflow.apache.org/docs/apache-airflow...</td>\n",
       "      <td>Public Interface of Airflow — Airflow Document...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Database Migrations\\nDatabase ERD Schema\\n\\n\\n...</td>\n",
       "      <td>https://airflow.apache.org/docs/apache-airflow...</td>\n",
       "      <td>Public Interface of Airflow — Airflow Document...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Timetables\\nairflow.timetables\\n\\n\\nListeners\\...</td>\n",
       "      <td>https://airflow.apache.org/docs/apache-airflow...</td>\n",
       "      <td>Public Interface of Airflow — Airflow Document...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        page_content  \\\n",
       "0  Public Interface of Airflow — Airflow Document...   \n",
       "1  Announcements\\n                            \\n\\...   \n",
       "2  Task Instance Keys\\nairflow.models.taskinstanc...   \n",
       "3  Database Migrations\\nDatabase ERD Schema\\n\\n\\n...   \n",
       "4  Timetables\\nairflow.timetables\\n\\n\\nListeners\\...   \n",
       "\n",
       "                                              source  \\\n",
       "0  https://airflow.apache.org/docs/apache-airflow...   \n",
       "1  https://airflow.apache.org/docs/apache-airflow...   \n",
       "2  https://airflow.apache.org/docs/apache-airflow...   \n",
       "3  https://airflow.apache.org/docs/apache-airflow...   \n",
       "4  https://airflow.apache.org/docs/apache-airflow...   \n",
       "\n",
       "                                               title language  \n",
       "0  Public Interface of Airflow — Airflow Document...       en  \n",
       "1  Public Interface of Airflow — Airflow Document...       en  \n",
       "2  Public Interface of Airflow — Airflow Document...       en  \n",
       "3  Public Interface of Airflow — Airflow Document...       en  \n",
       "4  Public Interface of Airflow — Airflow Document...       en  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "page_contents = []\n",
    "sources = []\n",
    "titles = []\n",
    "languages = []\n",
    "\n",
    "for document in splitted_documents:\n",
    "    page_contents.append(document.page_content)\n",
    "    if document.metadata:\n",
    "        sources.append(document.metadata.get('source', \"Unknown\"))\n",
    "        titles.append(document.metadata.get('title', \"Unknown\"))\n",
    "        languages.append(document.metadata.get('language', \"Unknown\"))\n",
    "\n",
    "documents_df = pd.DataFrame({\n",
    "    'page_content': page_contents,\n",
    "    'source': sources,\n",
    "    'title': titles,\n",
    "    'language': languages\n",
    "})\n",
    "documents_df.fillna(\"Unknown\", inplace=True)\n",
    "documents_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "de23fd28-8073-4b58-8860-259e2c599823",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace \\n and \\t with a space\n",
    "documents_df[\"page_content\"] = documents_df[\"page_content\"].replace('\\n', ' ', regex=True)\n",
    "documents_df[\"page_content\"] = documents_df[\"page_content\"].replace('\\t', ' ', regex=True)\n",
    "# Remove leading and trailing spaces\n",
    "documents_df[\"page_content\"] = documents_df[\"page_content\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2cad5690-fb66-4655-a09d-b0e06e9d0c91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>page_content</th>\n",
       "      <th>source</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Public Interface of Airflow — Airflow Document...</td>\n",
       "      <td>https://airflow.apache.org/docs/apache-airflow...</td>\n",
       "      <td>Public Interface of Airflow — Airflow Document...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Announcements                                 ...</td>\n",
       "      <td>https://airflow.apache.org/docs/apache-airflow...</td>\n",
       "      <td>Public Interface of Airflow — Airflow Document...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Task Instance Keys airflow.models.taskinstance...</td>\n",
       "      <td>https://airflow.apache.org/docs/apache-airflow...</td>\n",
       "      <td>Public Interface of Airflow — Airflow Document...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Database Migrations Database ERD Schema       ...</td>\n",
       "      <td>https://airflow.apache.org/docs/apache-airflow...</td>\n",
       "      <td>Public Interface of Airflow — Airflow Document...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Timetables airflow.timetables   Listeners Extr...</td>\n",
       "      <td>https://airflow.apache.org/docs/apache-airflow...</td>\n",
       "      <td>Public Interface of Airflow — Airflow Document...</td>\n",
       "      <td>en</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        page_content  \\\n",
       "0  Public Interface of Airflow — Airflow Document...   \n",
       "1  Announcements                                 ...   \n",
       "2  Task Instance Keys airflow.models.taskinstance...   \n",
       "3  Database Migrations Database ERD Schema       ...   \n",
       "4  Timetables airflow.timetables   Listeners Extr...   \n",
       "\n",
       "                                              source  \\\n",
       "0  https://airflow.apache.org/docs/apache-airflow...   \n",
       "1  https://airflow.apache.org/docs/apache-airflow...   \n",
       "2  https://airflow.apache.org/docs/apache-airflow...   \n",
       "3  https://airflow.apache.org/docs/apache-airflow...   \n",
       "4  https://airflow.apache.org/docs/apache-airflow...   \n",
       "\n",
       "                                               title language  \n",
       "0  Public Interface of Airflow — Airflow Document...       en  \n",
       "1  Public Interface of Airflow — Airflow Document...       en  \n",
       "2  Public Interface of Airflow — Airflow Document...       en  \n",
       "3  Public Interface of Airflow — Airflow Document...       en  \n",
       "4  Public Interface of Airflow — Airflow Document...       en  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c6ee6180-cf0d-4afd-8138-c2d88d22ad0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "page_content    0\n",
       "source          0\n",
       "title           0\n",
       "language        0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c7999a66-e2d9-431d-9ec1-86905749ca34",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents_df.to_parquet('./parquets/documents_with_rec-char-split.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0422fd15-43d5-4dd6-b792-3a1d67fa65f4",
   "metadata": {},
   "source": [
    "## Storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a8162035-d238-4557-b066-58a649599eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "client = chromadb.Client(Settings(\n",
    "    chroma_db_impl=\"duckdb+parquet\",\n",
    "    persist_directory=\"./db/\"\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c878a393-b82c-4c69-a91f-16d25df820b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating collection: 'airflow_docs_stable'\n"
     ]
    }
   ],
   "source": [
    "collection_name = \"airflow_docs_stable\"\n",
    "if len(client.list_collections()) > 0 and collection_name in [\n",
    "    client.list_collections()[0].name\n",
    "]:\n",
    "    client.delete_collection(name=collection_name)\n",
    "print(f\"Creating collection: '{collection_name}'\")\n",
    "collection = client.create_collection(name=collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "67c648e1-3a32-461d-8a33-118667f1c8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.cache/chroma/onnx_models/all-MiniLM-L6-v2/onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:05<00:00, 14.0MiB/s]\n"
     ]
    }
   ],
   "source": [
    "for index, row in documents_df.iterrows():\n",
    "    if pd.notnull(row['source']) and pd.notnull(row['title']) and pd.notnull(row['language']):\n",
    "        metadata = {\n",
    "            'source': row['source'],\n",
    "            'title': row['title'],\n",
    "            'language': row['language']\n",
    "        }\n",
    "    collection.add(\n",
    "        documents=[row['page_content']],\n",
    "        metadatas=[metadata],\n",
    "        ids=[str(index)],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "287c88d9-1198-4e88-961c-e1b47c965839",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.persist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ba79850-be47-4cba-8395-08f728755a5a",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0bf6c074-550c-421a-b493-038d359041c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using the Public Interface for DAG Authors¶  DAGs¶ The DAG is Airflow’s core entity that represents a recurring workflow. You can create a DAG by instantiating the DAG class in your DAG file. You can also instantiate them via :class::~airflow.models.dagbag.DagBag class that reads DAGs from a file or a folder. DAGs can also have parameters specified via :class::~airflow.models.param.Param class. Airflow has a set of example DAGs that you can use to learn how to write DAGs   airflow.example_dags   You can read more about DAGs in DAGs. References for the modules used in DAGs are here:   airflow.models.dag airflow.models.dagbag airflow.models.param     Operators¶ Operators allow for generation of certain types of tasks that become nodes in the DAG when instantiated. There are 3 main types of operators:\n",
      "\n",
      "Positional Arguments¶  dag_id The id of the dag  execution_date The execution date of the DAG (optional)     Named Arguments¶  -c, --conf JSON string that gets pickled into the DagRun’s conf attribute  --imgcat-dagrun After completing the dag run, prints a diagram on the screen for the current DAG Run using the imgcat tool. Default: False  --save-dagrun After completing the backfill, saves the diagram for current DAG Run to the indicated file.  --show-dagrun After completing the backfill, shows the diagram for current DAG Run. The diagram is in DOT language Default: False  -S, --subdir File location or directory from which to look for the dag. Defaults to ‘[AIRFLOW_HOME]/dags’ where [AIRFLOW_HOME] is the value you set for ‘AIRFLOW_HOME’ config you set in ‘airflow.cfg’ Default: “[AIRFLOW_HOME]/dags”  -v, --verbose Make logging output more verbose Default: False\n",
      "\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n"
     ]
    }
   ],
   "source": [
    "question = \"How to create a DAG?\"\n",
    "results = collection.query(\n",
    "    query_texts=[question],\n",
    "    n_results=3,\n",
    ")\n",
    "formatted_result = \"\\n\\n\".join(results[\"documents\"][0])\n",
    "print(formatted_result)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
