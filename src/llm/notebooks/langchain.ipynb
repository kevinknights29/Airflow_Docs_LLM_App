{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a80e960-cb9c-4eba-8b53-402614995fc8",
   "metadata": {},
   "source": [
    "# Working with LLMs and LangChain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8e8ddb-8b47-477b-b51e-048dacb653cd",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "67345dbc-d90e-4918-9e94-acced1843185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: accelerate in /home/jovyan/.local/lib/python3.11/site-packages (0.20.3)\n",
      "Requirement already satisfied: transformers[torch] in /home/jovyan/.local/lib/python3.11/site-packages (4.30.2)\n",
      "Requirement already satisfied: torch in /home/jovyan/.local/lib/python3.11/site-packages (2.0.1)\n",
      "Requirement already satisfied: sentencepiece in /home/jovyan/.local/lib/python3.11/site-packages (0.1.99)\n",
      "Requirement already satisfied: chromadb in /home/jovyan/.local/lib/python3.11/site-packages (0.3.26)\n",
      "Requirement already satisfied: langchain in /home/jovyan/.local/lib/python3.11/site-packages (0.0.228)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.11/site-packages (from accelerate) (1.24.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.11/site-packages (from accelerate) (23.1)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.11/site-packages (from accelerate) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /opt/conda/lib/python3.11/site-packages (from accelerate) (6.0)\n",
      "Requirement already satisfied: filelock in /home/jovyan/.local/lib/python3.11/site-packages (from transformers[torch]) (3.12.2)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.14.1 in /home/jovyan/.local/lib/python3.11/site-packages (from transformers[torch]) (0.16.4)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jovyan/.local/lib/python3.11/site-packages (from transformers[torch]) (2023.6.3)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (2.31.0)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/jovyan/.local/lib/python3.11/site-packages (from transformers[torch]) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/jovyan/.local/lib/python3.11/site-packages (from transformers[torch]) (0.3.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.11/site-packages (from transformers[torch]) (4.65.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from torch) (4.7.0)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch) (3.1.2)\n",
      "Requirement already satisfied: pandas>=1.3 in /opt/conda/lib/python3.11/site-packages (from chromadb) (2.0.3)\n",
      "Requirement already satisfied: pydantic>=1.9 in /home/jovyan/.local/lib/python3.11/site-packages (from chromadb) (1.10.11)\n",
      "Requirement already satisfied: hnswlib>=0.7 in /home/jovyan/.local/lib/python3.11/site-packages (from chromadb) (0.7.0)\n",
      "Requirement already satisfied: clickhouse-connect>=0.5.7 in /home/jovyan/.local/lib/python3.11/site-packages (from chromadb) (0.6.6)\n",
      "Requirement already satisfied: duckdb>=0.7.1 in /home/jovyan/.local/lib/python3.11/site-packages (from chromadb) (0.8.1)\n",
      "Requirement already satisfied: fastapi>=0.85.1 in /home/jovyan/.local/lib/python3.11/site-packages (from chromadb) (0.100.0)\n",
      "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /home/jovyan/.local/lib/python3.11/site-packages (from chromadb) (0.22.0)\n",
      "Requirement already satisfied: posthog>=2.4.0 in /home/jovyan/.local/lib/python3.11/site-packages (from chromadb) (3.0.1)\n",
      "Requirement already satisfied: pulsar-client>=3.1.0 in /home/jovyan/.local/lib/python3.11/site-packages (from chromadb) (3.2.0)\n",
      "Requirement already satisfied: onnxruntime>=1.14.1 in /home/jovyan/.local/lib/python3.11/site-packages (from chromadb) (1.15.1)\n",
      "Requirement already satisfied: overrides>=7.3.1 in /opt/conda/lib/python3.11/site-packages (from chromadb) (7.3.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.0.17)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /home/jovyan/.local/lib/python3.11/site-packages (from langchain) (3.8.4)\n",
      "Requirement already satisfied: dataclasses-json<0.6.0,>=0.5.7 in /home/jovyan/.local/lib/python3.11/site-packages (from langchain) (0.5.9)\n",
      "Requirement already satisfied: langchainplus-sdk<0.0.21,>=0.0.20 in /home/jovyan/.local/lib/python3.11/site-packages (from langchain) (0.0.20)\n",
      "Requirement already satisfied: numexpr<3.0.0,>=2.8.4 in /opt/conda/lib/python3.11/site-packages (from langchain) (2.8.4)\n",
      "Requirement already satisfied: openapi-schema-pydantic<2.0,>=1.2 in /home/jovyan/.local/lib/python3.11/site-packages (from langchain) (1.2.4)\n",
      "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /home/jovyan/.local/lib/python3.11/site-packages (from langchain) (8.2.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /opt/conda/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.1.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/jovyan/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/jovyan/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/jovyan/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/jovyan/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/jovyan/.local/lib/python3.11/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.11/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.5.7)\n",
      "Requirement already satisfied: importlib-metadata in /opt/conda/lib/python3.11/site-packages (from clickhouse-connect>=0.5.7->chromadb) (6.7.0)\n",
      "Requirement already satisfied: urllib3>=1.26 in /opt/conda/lib/python3.11/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2.0.3)\n",
      "Requirement already satisfied: pytz in /opt/conda/lib/python3.11/site-packages (from clickhouse-connect>=0.5.7->chromadb) (2023.3)\n",
      "Requirement already satisfied: zstandard in /opt/conda/lib/python3.11/site-packages (from clickhouse-connect>=0.5.7->chromadb) (0.19.0)\n",
      "Requirement already satisfied: lz4 in /opt/conda/lib/python3.11/site-packages (from clickhouse-connect>=0.5.7->chromadb) (4.3.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.3.0 in /home/jovyan/.local/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (3.19.0)\n",
      "Requirement already satisfied: marshmallow-enum<2.0.0,>=1.5.1 in /home/jovyan/.local/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (1.5.1)\n",
      "Requirement already satisfied: typing-inspect>=0.4.0 in /home/jovyan/.local/lib/python3.11/site-packages (from dataclasses-json<0.6.0,>=0.5.7->langchain) (0.9.0)\n",
      "Requirement already satisfied: starlette<0.28.0,>=0.27.0 in /home/jovyan/.local/lib/python3.11/site-packages (from fastapi>=0.85.1->chromadb) (0.27.0)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.14.1->transformers[torch]) (2023.6.0)\n",
      "Requirement already satisfied: coloredlogs in /home/jovyan/.local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (15.0.1)\n",
      "Requirement already satisfied: flatbuffers in /home/jovyan/.local/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (23.5.26)\n",
      "Requirement already satisfied: protobuf in /opt/conda/lib/python3.11/site-packages (from onnxruntime>=1.14.1->chromadb) (4.23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.3->chromadb) (2.8.2)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /opt/conda/lib/python3.11/site-packages (from pandas>=1.3->chromadb) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (1.16.0)\n",
      "Requirement already satisfied: monotonic>=1.5 in /home/jovyan/.local/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (1.6)\n",
      "Requirement already satisfied: backoff>=1.10.0 in /home/jovyan/.local/lib/python3.11/site-packages (from posthog>=2.4.0->chromadb) (2.2.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->transformers[torch]) (3.4)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.11/site-packages (from SQLAlchemy<3,>=1.4->langchain) (2.0.2)\n",
      "Requirement already satisfied: click>=7.0 in /opt/conda/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (8.1.3)\n",
      "Requirement already satisfied: h11>=0.8 in /home/jovyan/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.14.0)\n",
      "Requirement already satisfied: httptools>=0.5.0 in /home/jovyan/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.6.0)\n",
      "Requirement already satisfied: python-dotenv>=0.13 in /home/jovyan/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (1.0.0)\n",
      "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /home/jovyan/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.17.0)\n",
      "Requirement already satisfied: watchfiles>=0.13 in /home/jovyan/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (0.19.0)\n",
      "Requirement already satisfied: websockets>=10.4 in /home/jovyan/.local/lib/python3.11/site-packages (from uvicorn[standard]>=0.18.3->chromadb) (11.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch) (2.1.3)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch) (1.3.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /opt/conda/lib/python3.11/site-packages (from starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (3.7.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/jovyan/.local/lib/python3.11/site-packages (from typing-inspect>=0.4.0->dataclasses-json<0.6.0,>=0.5.7->langchain) (1.0.0)\n",
      "Requirement already satisfied: humanfriendly>=9.1 in /home/jovyan/.local/lib/python3.11/site-packages (from coloredlogs->onnxruntime>=1.14.1->chromadb) (10.0)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.11/site-packages (from importlib-metadata->clickhouse-connect>=0.5.7->chromadb) (3.15.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.11/site-packages (from anyio<5,>=3.4.0->starlette<0.28.0,>=0.27.0->fastapi>=0.85.1->chromadb) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install accelerate transformers[torch] torch sentencepiece chromadb langchain --user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8fa1c09-5d6c-4ba6-a0f7-6b8502794259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xformers in /opt/conda/lib/python3.11/site-packages (0.0.20)\n",
      "Requirement already satisfied: sentence_transformers in /opt/conda/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: lark in /opt/conda/lib/python3.11/site-packages (1.1.5)\n",
      "Requirement already satisfied: torch>=1.12 in /home/jovyan/.local/lib/python3.11/site-packages (from xformers) (2.0.1)\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.11/site-packages (from xformers) (1.24.4)\n",
      "Requirement already satisfied: pyre-extensions==0.0.29 in /opt/conda/lib/python3.11/site-packages (from xformers) (0.0.29)\n",
      "Requirement already satisfied: typing-inspect in /home/jovyan/.local/lib/python3.11/site-packages (from pyre-extensions==0.0.29->xformers) (0.9.0)\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.11/site-packages (from pyre-extensions==0.0.29->xformers) (4.7.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /home/jovyan/.local/lib/python3.11/site-packages (from sentence_transformers) (4.30.2)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torchvision in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (0.15.2)\n",
      "Requirement already satisfied: scikit-learn in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (1.2.2)\n",
      "Requirement already satisfied: scipy in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.11/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /home/jovyan/.local/lib/python3.11/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /home/jovyan/.local/lib/python3.11/site-packages (from sentence_transformers) (0.16.4)\n",
      "Requirement already satisfied: filelock in /home/jovyan/.local/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.12.2)\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.6.0)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.11/site-packages (from torch>=1.12->xformers) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.11/site-packages (from torch>=1.12->xformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.11/site-packages (from torch>=1.12->xformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/jovyan/.local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2023.6.3)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /home/jovyan/.local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.3)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /home/jovyan/.local/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.1)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.11/site-packages (from nltk->sentence_transformers) (8.1.3)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.11/site-packages (from nltk->sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.11/site-packages (from torchvision->sentence_transformers) (9.5.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.11/site-packages (from jinja2->torch>=1.12->xformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.5.7)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.11/site-packages (from sympy->torch>=1.12->xformers) (1.3.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /home/jovyan/.local/lib/python3.11/site-packages (from typing-inspect->pyre-extensions==0.0.29->xformers) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# need to be run after the above dependencies installation\n",
    "%pip install xformers sentence_transformers lark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14c377d0-be79-4cba-a15a-33e7aa58c844",
   "metadata": {},
   "source": [
    "## Loading Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f3c8fab6-bf89-4ced-8c85-e7daedfff072",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline\n",
    "from langchain import HuggingFacePipeline\n",
    "\n",
    "model=\"bigscience/bloom-1b1\"\n",
    "text_gen_pipeline = pipeline(\n",
    "    model=model, \n",
    "    model_kwargs= {\n",
    "        \"device_map\": \"auto\", \n",
    "        \"load_in_8bit\": False, \n",
    "        \"temperature\": 0.1,\n",
    "        \"top_p\": 1.0,\n",
    "        \"max_length\": 1024,\n",
    "        \n",
    "    },\n",
    "    max_new_tokens=2048)\n",
    "\n",
    "llm = HuggingFacePipeline(pipeline=text_gen_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc653fe8-20f7-489a-be7d-091b01b93dda",
   "metadata": {},
   "source": [
    "## Testing Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "01b68f07-3943-4079-b74c-d56ef2f49576",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " First, we need to know what is electroencephalography. Electroencephalography is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-magnetic recording that is used to measure the electrical activity of the brain. It is a type of electro-m\n"
     ]
    }
   ],
   "source": [
    "from langchain import PromptTemplate, LLMChain\n",
    "\n",
    "template = (\n",
    "    \"Question: {question}\"\n",
    "    \"Answer: Let's think step by step.\"\n",
    ")\n",
    "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
    "\n",
    "llm_chain = LLMChain(prompt=prompt, llm=llm)\n",
    "\n",
    "question = \"What is electroencephalography?\"\n",
    "print(llm_chain.run(question))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "445b649e-c46f-4b52-ab3d-eff1eae7c5a2",
   "metadata": {},
   "source": [
    "## Accessing Embeddings Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7fbc77b7-9369-4c34-8e36-5753f3173610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents: 1474\n"
     ]
    }
   ],
   "source": [
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings.sentence_transformer import SentenceTransformerEmbeddings\n",
    "\n",
    "embeddings = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "vector_db = Chroma(\n",
    "    collection_name=\"airflow_docs_stable\",\n",
    "    persist_directory=\"./db/\",\n",
    "    embedding_function=embeddings,\n",
    ")\n",
    "print(f\"Documents: {vector_db._collection.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cc58167-765e-4098-8b8d-615e1f0ae735",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      "\n",
      "However, you should always use data_interval_start or data_interval_end if possible, since those names are semantically more correct and less prone to misunderstandings. Note that ds (the YYYY-MM-DD form of data_interval_start) refers to date *string*, not date *start* as may be confusing to some.  Tip For more information on logical date, see Data Interval and Running DAGs.    How to create DAGs dynamically?¶ Airflow looks in your DAGS_FOLDER for modules that contain DAG objects in their global namespace and adds the objects it finds in the DagBag. Knowing this, all we need is a way to dynamically assign variable in the global namespace. This is easily done in python using the globals() function for the standard library, which behaves like a simple dictionary. def create_dag(dag_id):     \"\"\"     A function returning a DAG object.     \"\"\"      return DAG(dag_id)   for i in range(10):     dag_id = f\"foo_{i}\"     globals()[dag_id] = DAG(dag_id)\n",
      "\n",
      "Testing a DAG¶ Airflow users should treat DAGs as production level code, and DAGs should have various associated tests to ensure that they produce expected results. You can write a wide variety of tests for a DAG. Let’s take a look at some of them.  DAG Loader Test¶ This test should ensure that your DAG does not contain a piece of code that raises error while loading. No additional code needs to be written by the user to run this test. python your-dag-file.py\n"
     ]
    }
   ],
   "source": [
    "question = \"Python Code to create a Dag Class\"\n",
    "docs = vector_db.similarity_search(question, k=3)\n",
    "result_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "print(result_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ec0881c-6354-4018-82f4-7dea6e1a75ab",
   "metadata": {},
   "source": [
    "## Experimenting with other retrival methods"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66d64bf-8daf-4f4d-811f-2371aa24f155",
   "metadata": {},
   "source": [
    "### Max Marginal Relevance\n",
    "Research Paper: https://www.cs.cmu.edu/~jgc/publication/The_Use_MMR_Diversity_Based_LTMIR_1998.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3842a762-dc99-41a0-8495-73a6931c07ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      "\n",
      "However, you should always use data_interval_start or data_interval_end if possible, since those names are semantically more correct and less prone to misunderstandings. Note that ds (the YYYY-MM-DD form of data_interval_start) refers to date *string*, not date *start* as may be confusing to some.  Tip For more information on logical date, see Data Interval and Running DAGs.    How to create DAGs dynamically?¶ Airflow looks in your DAGS_FOLDER for modules that contain DAG objects in their global namespace and adds the objects it finds in the DagBag. Knowing this, all we need is a way to dynamically assign variable in the global namespace. This is easily done in python using the globals() function for the standard library, which behaves like a simple dictionary. def create_dag(dag_id):     \"\"\"     A function returning a DAG object.     \"\"\"      return DAG(dag_id)   for i in range(10):     dag_id = f\"foo_{i}\"     globals()[dag_id] = DAG(dag_id)\n",
      "\n",
      "Testing a DAG¶ Airflow users should treat DAGs as production level code, and DAGs should have various associated tests to ensure that they produce expected results. You can write a wide variety of tests for a DAG. Let’s take a look at some of them.  DAG Loader Test¶ This test should ensure that your DAG does not contain a piece of code that raises error while loading. No additional code needs to be written by the user to run this test. python your-dag-file.py\n"
     ]
    }
   ],
   "source": [
    "question = \"Python Code to create a Dag Class\"\n",
    "docs = vector_db.max_marginal_relevance_search(question, k=3, fetch_k=5)\n",
    "result_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "print(result_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a53a109-ba50-452a-b288-d8f6f4d9bc7f",
   "metadata": {},
   "source": [
    "### Metadata filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "be6cb721-aca9-480f-a573-172c4fc86cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'https://airflow.apache.org/docs/apache-airflow/stable/faq.html', 'title': 'FAQ — Airflow Documentation', 'language': 'en'}\n",
      "{'source': 'https://airflow.apache.org/docs/apache-airflow/stable/faq.html', 'title': 'FAQ — Airflow Documentation', 'language': 'en'}\n",
      "{'source': 'https://airflow.apache.org/docs/apache-airflow/stable/best-practices.html', 'title': 'Best Practices — Airflow Documentation', 'language': 'en'}\n"
     ]
    }
   ],
   "source": [
    "question = \"Python Code to create a Dag Class\"\n",
    "docs = vector_db.similarity_search(question, k=3)\n",
    "for doc in docs:\n",
    "    print(doc.metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ceffa50-6f07-40b9-99fe-4d353c200e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers.self_query.base import SelfQueryRetriever\n",
    "from langchain.chains.query_constructor.base import AttributeInfo\n",
    "\n",
    "metadata_field_info = [\n",
    "    AttributeInfo(\n",
    "        name=\"source\",\n",
    "        description=\"The url webpage the chunk is from\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"title\",\n",
    "        description=\"The title of the of documentation entry\",\n",
    "        type=\"string\",\n",
    "    ),\n",
    "    AttributeInfo(\n",
    "        name=\"language\",\n",
    "        description=\"The language the text is written in\",\n",
    "        type=\"string\",\n",
    "    )\n",
    "]\n",
    "\n",
    "document_content_desc = \"Documentation text\"\n",
    "retriever = SelfQueryRetriever.from_llm(\n",
    "    llm,\n",
    "    vector_db,\n",
    "    document_content_desc,\n",
    "    metadata_field_info,\n",
    "    verbose=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5be2374e-1a32-485f-821b-b94047e96706",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.11/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "OutputParserException",
     "evalue": "Parsing text\n```json\n{\n    \"query\": \"documentation text\",\n    \"filter\": \"and(or(eq(\\\"source\\\", \\\"http://pypi.python.org/pypi?%3Apypi%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A\n raised following error:\nGot invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/langchain/output_parsers/json.py:52\u001b[0m, in \u001b[0;36mparse_and_check_json_markdown\u001b[0;34m(text, expected_keys)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     json_obj \u001b[38;5;241m=\u001b[39m \u001b[43mparse_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/langchain/output_parsers/json.py:34\u001b[0m, in \u001b[0;36mparse_json_markdown\u001b[0;34m(json_string)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# Parse the JSON string into a Python dictionary\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m parsed \u001b[38;5;241m=\u001b[39m \u001b[43mjson\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mjson_str\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m parsed\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/json/__init__.py:346\u001b[0m, in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    344\u001b[0m         parse_int \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m parse_float \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    345\u001b[0m         parse_constant \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m object_pairs_hook \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m kw):\n\u001b[0;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_default_decoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    347\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/json/decoder.py:337\u001b[0m, in \u001b[0;36mJSONDecoder.decode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    333\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Return the Python representation of ``s`` (a ``str`` instance\u001b[39;00m\n\u001b[1;32m    334\u001b[0m \u001b[38;5;124;03mcontaining a JSON document).\u001b[39;00m\n\u001b[1;32m    335\u001b[0m \n\u001b[1;32m    336\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m--> 337\u001b[0m obj, end \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraw_decode\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_w\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    338\u001b[0m end \u001b[38;5;241m=\u001b[39m _w(s, end)\u001b[38;5;241m.\u001b[39mend()\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/json/decoder.py:355\u001b[0m, in \u001b[0;36mJSONDecoder.raw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m--> 355\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m JSONDecodeError(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpecting value\u001b[39m\u001b[38;5;124m\"\u001b[39m, s, err\u001b[38;5;241m.\u001b[39mvalue) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    356\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m obj, end\n",
      "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/langchain/chains/query_constructor/base.py:37\u001b[0m, in \u001b[0;36mStructuredQueryOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     36\u001b[0m allowed_keys \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfilter\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlimit\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m---> 37\u001b[0m parsed \u001b[38;5;241m=\u001b[39m \u001b[43mparse_and_check_json_markdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpected_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/langchain/output_parsers/json.py:54\u001b[0m, in \u001b[0;36mparse_and_check_json_markdown\u001b[0;34m(text, expected_keys)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m json\u001b[38;5;241m.\u001b[39mJSONDecodeError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 54\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGot invalid JSON object. Error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m expected_keys:\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Got invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mOutputParserException\u001b[0m                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m question \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPython Code to create a Dag Class\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m docs \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/langchain/schema/retriever.py:181\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    180\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_error(e)\n\u001b[0;32m--> 181\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_retriever_end(\n\u001b[1;32m    184\u001b[0m         result,\n\u001b[1;32m    185\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    186\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/langchain/schema/retriever.py:174\u001b[0m, in \u001b[0;36mBaseRetriever.get_relevant_documents\u001b[0;34m(self, query, callbacks, tags, metadata, **kwargs)\u001b[0m\n\u001b[1;32m    172\u001b[0m _kwargs \u001b[38;5;241m=\u001b[39m kwargs \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expects_other_args \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_arg_supported:\n\u001b[0;32m--> 174\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_relevant_documents\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    175\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m_kwargs\u001b[49m\n\u001b[1;32m    176\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    178\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_relevant_documents(query, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/langchain/retrievers/self_query/base.py:100\u001b[0m, in \u001b[0;36mSelfQueryRetriever._get_relevant_documents\u001b[0;34m(self, query, run_manager)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Get documents relevant for a query.\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    List of relevant documents\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     97\u001b[0m inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm_chain\u001b[38;5;241m.\u001b[39mprep_inputs({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery\u001b[39m\u001b[38;5;124m\"\u001b[39m: query})\n\u001b[1;32m     98\u001b[0m structured_query \u001b[38;5;241m=\u001b[39m cast(\n\u001b[1;32m     99\u001b[0m     StructuredQuery,\n\u001b[0;32m--> 100\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mllm_chain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict_and_parse\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m    103\u001b[0m )\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose:\n\u001b[1;32m    105\u001b[0m     \u001b[38;5;28mprint\u001b[39m(structured_query)\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/langchain/chains/llm.py:281\u001b[0m, in \u001b[0;36mLLMChain.predict_and_parse\u001b[0;34m(self, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    279\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpredict(callbacks\u001b[38;5;241m=\u001b[39mcallbacks, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    280\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprompt\u001b[38;5;241m.\u001b[39moutput_parser \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 281\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprompt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_parser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/langchain/chains/query_constructor/base.py:50\u001b[0m, in \u001b[0;36mStructuredQueryOutputParser.parse\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m StructuredQuery(\n\u001b[1;32m     47\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m{k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m parsed\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m allowed_keys}\n\u001b[1;32m     48\u001b[0m     )\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 50\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m OutputParserException(\n\u001b[1;32m     51\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mParsing text\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mtext\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m raised following error:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     52\u001b[0m     )\n",
      "\u001b[0;31mOutputParserException\u001b[0m: Parsing text\n```json\n{\n    \"query\": \"documentation text\",\n    \"filter\": \"and(or(eq(\\\"source\\\", \\\"http://pypi.python.org/pypi?%3Apypi%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A%3A\n raised following error:\nGot invalid JSON object. Error: Expecting value: line 1 column 1 (char 0)"
     ]
    }
   ],
   "source": [
    "question = \"Python Code to create a Dag Class\"\n",
    "docs = retriever.get_relevant_documents(question)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14339189-c14a-4744-9b26-9989c6512fbf",
   "metadata": {},
   "source": [
    "### Contextual Compreesion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f34937b4-b859-4ac6-8fa7-af8a1f1053e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.retrievers import ContextualCompressionRetriever\n",
    "from langchain.retrievers.document_compressors import LLMChainExtractor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "895db9cd-0ff6-4903-92fd-0eef66f18466",
   "metadata": {},
   "outputs": [],
   "source": [
    "compressor = LLMChainExtractor.from_llm(llm)\n",
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vector_db.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6d2ebe90-bd82-4939-84f9-023902ff27f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jovyan/.local/lib/python3.11/site-packages/langchain/chains/llm.py:275: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default\n",
      "\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      "\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      "\n",
      "> DAG(dag_id=\"example\", auto_register=False):\n",
      ">     @dag def dag_maker():    ...   dag2 = dag_maker()   can become with DAG(dag_id=\"example\"):    ...   @dag def dag_maker():    ...   dag_maker()   If you want to disable the behaviour for any reason then set auto_register=False on the dag: # This dag will not be picked up by Airflow as it's not assigned to a variable with DAG(dag_id=\"example\", auto_register=False):    ...     Deprecation of schedule_interval and timetable arguments (#25410)¶ We added new DAG argument schedule that can accept a cron expression, timedelta object, timetable object, or list of dataset objects. Arguments schedule_interval and timetable are deprecated. If you previously used the @daily cron preset, your DAG may have looked like this: with DAG(     dag_id=\"my_example\",     start_date=datetime(2021, 1, 1),     schedule_interval=\"@daily\", ):    ...\n",
      ">>>\n",
      "Extracted relevant parts:\n",
      "> DAG(dag_id=\"example\", auto_register=False):\n",
      ">     @dag def dag_maker():    ...   dag2 = dag_maker()   can become with DAG(dag_id=\"example\"):    ...   @dag def dag_maker():    ...   dag_maker()   If you want to disable the behaviour for any reason then set auto_register=False on the dag: # This dag will not be picked up by Airflow as it's not assigned to a variable with DAG(dag_id=\"example\", auto_register=False):    ...     Deprecation of schedule_interval and timetable arguments (#25410)¶ We added new DAG argument schedule that can accept a cron expression, timedelta object, timetable object, or list of dataset objects. Arguments schedule_interval and timetable are deprecated. If you previously used the @daily cron preset, your DAG may have looked like this: with DAG(     dag_id=\"my_example\",     start_date=datetime(2021, 1, 1),     schedule_interval=\"@daily\", ):    ...\n",
      ">>>\n",
      "Extracted relevant parts:\n",
      "> DAG(dag_id=\"example\", auto_register=False):\n",
      ">     @dag def dag_maker():    ...   dag2 = dag_maker()   can become with DAG(dag_id=\"example\"):    ...   @dag def dag_maker():    ...   dag_maker()   If you want to disable the behaviour for any reason then set auto_register=False on the dag: # This dag will not be picked up by Airflow as it's not assigned to a variable with DAG(dag_id=\"example\", auto_register=False):    ...     Deprecation of schedule_interval and timetable arguments (#25410)¶ We added new DAG argument schedule that can accept a cron expression, timedelta object, timetable object, or list of dataset objects. Arguments schedule_interval and timetable are deprecated. If you previously used the @daily cron preset, your DAG may have looked like this: with DAG(     dag_id=\"my_example\",     start_date=datetime(2021, 1, 1),     schedule_interval=\"@daily\", ):    ...\n",
      ">>>\n",
      "Extracted relevant parts:\n",
      "> DAG(dag_id=\"example\", auto_register=False):\n",
      ">     @dag def dag_maker():    ...   dag2 = dag_maker()   can become with DAG(dag_id=\"example\"):    ...   @dag def dag_maker():    ...   dag_maker()   If you want to disable the behaviour for any reason then set auto_register=False on the dag: # This dag will not be picked up by Airflow as it's not assigned to a variable with DAG(dag_id=\"example\", auto_register=False):    ...     Deprecation of schedule_interval and timetable arguments (#25410)¶ We added new DAG argument schedule that can accept a cron expression, timedelta object, timetable object, or list of dataset objects. Arguments schedule_interval and timetable are deprecated. If you previously used the @daily cron preset, your DAG may have looked like this: with DAG(     dag_id=\"my_example\",     start_date=datetime(2021, 1, 1),     schedule_interval=\"@daily\", ):    ...\n",
      ">>>\n",
      "Extracted relevant parts:\n",
      "> DAG(dag_id=\"example\", auto_register=False):\n",
      ">     @dag def dag_maker():    ...   dag2 = dag_maker()   can become with DAG(dag_id=\"example\"):    ...   @dag def dag_maker():    ...   dag_maker()   If you want to disable the behaviour for any reason then set auto_register=False on the dag: # This dag will not be picked up by Airflow as it's not assigned to a variable with DAG(dag_id=\"example\", auto_register=False):    ...     Deprecation of schedule_interval and timetable arguments (#25410)¶ We added new DAG argument schedule that can accept a cron expression, timedelta object, timetable object, or list of dataset objects. Arguments schedule_interval and timetable are deprecated. If you previously used the @daily cron preset, your DAG may have looked like this: with DAG(     dag_id=\"my_example\",     start_date=datetime(2021, 1, 1),     schedule_interval=\"@daily\", ):    ...\n",
      ">>>\n",
      "Extracted relevant parts:\n",
      "> DAG(dag_id=\"example\", auto_register=False):\n",
      ">     @dag def dag_maker():    ...   dag2 = dag_maker()   can become with DAG(dag_id=\"example\"):    ...   @dag def dag_maker():    ...   dag_maker()   If you want to disable the behaviour for any reason then set auto_register=False on the dag: # This dag will not be picked up by Airflow as it's not assigned to a variable with DAG(dag_id=\"example\", auto_register=False):    ...     Deprecation of schedule_interval and timetable arguments (#25410)¶ We added new DAG argument schedule that can accept a cron expression, timedelta object, timetable object, or list of dataset objects. Arguments schedule_interval and timetable are deprecated. If you previously used the @daily cron preset, your DAG may have looked like this: with DAG(     dag_id=\"my_example\",     start_date=datetime(2021, 1, 1),     schedule_interval=\"@daily\", ):    ...\n",
      ">>>\n",
      "Extracted relevant parts:\n",
      "> DAG(dag_id=\"example\", auto_register=False):\n",
      ">     @dag def dag_maker():    ...   dag2 = dag_maker()   can become with DAG(dag_id=\"example\"):    ...   @dag def dag_maker():    ...   dag_maker()   If you want to disable the behaviour for any reason then set auto_register=False on the dag: # This dag will not be picked up by Airflow as it's not assigned to a variable with DAG(dag_id=\"example\", auto_register=False):    ...     Deprecation of schedule_interval and timetable arguments (#25410)¶ We added new DAG argument schedule that can accept a cron expression, timedelta object, timetable object, or list of dataset objects. Arguments schedule_interval and timetable are deprecated. If you previously used the @daily cron preset, your DAG may have looked like this: with DAG(     dag_id=\"my_example\",     start_date=datetime(2021, 1, 1),     schedule_interval=\"@daily\", ):    ...\n",
      ">>>\n",
      "Extracted relevant parts:\n",
      "> DAG(dag_id=\"example\", auto_register=False):\n",
      ">     @dag def dag_maker():    ...   dag2 = dag_maker()   can become with DAG(dag_id=\"example\"):    ...   @dag def dag_maker():    ...   dag_maker()   If you want to disable the behaviour for any reason then set auto_register=False on the dag: # This dag will not be picked up by Airflow as it's not assigned to a variable with DAG(dag_id=\"example\", auto_register=False):    ...     Deprecation of schedule_interval and timetable arguments (#25410)¶ We added new DAG argument schedule that can accept a cron expression, timedelta object, timetable object, or list of dataset objects. Arguments schedule_interval and timetable are deprecated. If you previously used the @daily cron preset, your DAG may have looked like this: with DAG(     dag_id=\"my_example\",     start_date=datetime(2021, 1, 1),     schedule_interval=\"@daily\", ):    ...\n",
      ">>>\n",
      "Extracted relevant parts:\n",
      "> DAG(dag_id=\"example\", auto_register=False):\n",
      ">     @dag def dag_maker():    ...   dag2 = dag_maker()   can become with DAG(dag_id=\"example\"):    ...   @dag def dag_maker():    ...   dag_maker()   If you want to disable the behaviour for any reason then set auto_register=False on the dag: # This dag will not be picked up by Airflow\n"
     ]
    }
   ],
   "source": [
    "question = \"Python Code to create a Dag Class\"\n",
    "docs = compression_retriever.get_relevant_documents(question)\n",
    "result_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "print(result_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20466fc4-7c65-41a4-a737-a2862f07e111",
   "metadata": {},
   "source": [
    "#### Adding MMR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "764dc27e-78a1-4af6-96ce-e5eeaef24ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "compression_retriever = ContextualCompressionRetriever(\n",
    "    base_compressor=compressor,\n",
    "    base_retriever=vector_db.as_retriever(search_type=\"mmr\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fb6e7600-a29d-4f39-a58f-324ca828fa73",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default_args):      dag = DAG(          dag_id,          schedule=schedule,          default_args=default_args,          pendulum.datetime(2021, 9, 13, tz=\"UTC\"),      )       with dag:           @task()          def hello_world():              print(\"Hello World\")              print(f\"This is DAG: {dag_number}\")           hello_world()       return dag       DAG construction¶\n",
      ">>>\n",
      "Extracted irrelevant parts:\n",
      ">>>\n",
      "dag_loader.py¶  from airflow import DAG  from airflow.decorators import task   import pendulum    def create_dag(dag_id, schedule, dag_number, default\n",
      "\n",
      ">>>\n",
      "Default http://localhost:8080  Environment Variable AIRFLOW__CLI__ENDPOINT_URL      [core]¶  allowed_deserialization_classes¶  New in version 2.5.0.  What classes can be imported during deserialization. This is a multi line value. The individual items will be parsed as regexp. Python built-in classes (like dict) are always allowed. Bare “.” will be replaced so you can set airflow.*.  Type string  Default airflow\\..*  Environment Variable AIRFLOW__CORE__ALLOWED_DESERIALIZATION_CLASSES     check_slas¶  New in version 1.10.8.  On each dagrun check against defined SLAs  Type string  Default True  Environment Variable AIRFLOW__CORE__CHECK_SLAS     compress_serialized_dags¶  New in version 2.3.0.  If True, serialized DAGs are compressed before writing to DB. Note: this will disable the DAG dependencies view  Type string  Default False  Environment Variable AIRFLOW__CORE__COMPRESS_SERIALIZED_DAGS     daemon_umask¶  New in version 2.3.4.\n",
      ">>>\n",
      "Extracted relevant parts:\n",
      ">>>\n",
      "Default http://localhost:8080  Environment Variable AIRFLOW__CLI__ENDPOINT_URL      [core]¶  allowed_deserialization_classes¶  New in version 2.5.0.  What classes can be imported during deserialization. This is a multi line value. The individual items will be parsed as regexp. Python built-in classes (like dict) are always allowed. Bare “.” will be replaced so you can set airflow.*.  Type string  Default airflow\\..*  Environment Variable AIRFLOW__CORE__ALLOWED_DESERIALIZATION_CLASSES     check_slas¶  New in version 1.10.8.  On each dagrun check against defined SLAs  Type string  Default True  Environment Variable AIRFLOW__CORE__CHECK_SLAS     compress_serialized_dags¶  New in version 2.3.0.  If True, serialized DAGs are compressed before writing to DB. Note: this will disable the DAG dependencies view  Type string  Default False  Environment Variable AIRFLOW__CORE__COMPRESS_SERIALIZED_DAGS     daemon_umask¶  New in version 2.3.4.\n",
      ">>>\n",
      "Extracted relevant parts:\n",
      ">>>\n",
      "Default http://localhost:8080  Environment Variable AIRFLOW__CLI__ENDPOINT_URL      [core]¶  allowed_deserialization_classes¶  New in version 2.5.0.  What classes can be imported during deserialization. This is a multi line value. The individual items will be parsed as regexp. Python built-in classes (like dict) are always allowed. Bare “.” will be replaced so you can set airflow.*.  Type string  Default airflow\\..*  Environment Variable AIRFLOW__CORE__ALLOWED_DESERIALIZATION_CLASSES     check_slas¶  New in version 1.10.8.  On each dagrun check against defined SLAs  Type string  Default True  Environment Variable AIRFLOW__CORE__CHECK_SLAS     compress_serialized_dags¶  New in version 2.3.0.  If True, serialized DAGs are compressed before writing to DB. Note: this will disable the DAG dependencies view  Type string  Default False  Environment Variable AIRFLOW__CORE__COMPRESS_SERIALIZED_DAGS     daemon_umask¶  New in version 2.3.4.\n",
      ">>>\n",
      "Extracted relevant parts:\n",
      ">>>\n",
      "Default http://localhost:8080  Environment Variable AIRFLOW__CLI__ENDPOINT_URL      [core]¶  allowed_deserialization_classes¶  New in version 2.5.0.  What classes can be imported during deserialization. This is a multi line value. The individual items will be parsed as regexp. Python built-in classes (like dict) are always allowed. Bare “.” will be replaced so you can set airflow.*.  Type string  Default airflow\\..*  Environment Variable AIRFLOW__CORE__ALLOWED_DESERIALIZATION_CLASSES     check_slas¶  New in version 1.10.8.  On each dagrun check against defined SLAs  Type string  Default True  Environment Variable AIRFLOW__CORE__CHECK_SLAS     compress_serialized_dags¶  New in version 2.3.0.  If True, serialized DAGs are compressed before writing to DB. Note: this will disable the DAG dependencies view  Type string  Default False  Environment Variable AIRFLOW__CORE__COMPRESS_SERIALIZED_DAGS     daemon_umask¶  New in version 2.3.4.\n",
      ">>>\n",
      "Extracted relevant parts:\n",
      ">>>\n",
      "Default http://localhost:8080  Environment Variable AIRFLOW__CLI__ENDPOINT_URL      [core]¶  allowed_deserialization_classes¶  New in version 2.5.0.  What classes can be imported during deserialization. This is a multi line value. The individual items will be parsed as regexp. Python built-in classes (like dict) are always allowed. Bare “.” will be replaced so you can set airflow.*.  Type string  Default airflow\\..*  Environment Variable AIRFLOW__CORE__ALLOWED_DESERIALIZATION_CLASSES     check_slas¶  New in version 1.10.8.  On each dagrun check against defined SLAs  Type string  Default True  Environment Variable AIRFLOW__CORE__CHECK_SLAS     compress_serialized_dags¶  New in version 2.3.0.  If True, serialized DAGs are compressed before writing to DB. Note: this will disable the DAG dependencies view  Type string  Default False  Environment Variable AIRFLOW__CORE__COMPRESS_SERIALIZED_DAGS     daemon_umask¶  New in version 2.3.4.\n",
      ">>>\n",
      "Extracted relevant parts:\n",
      ">>>\n",
      "Default http://localhost:8080  Environment Variable AIRFLOW__CLI__ENDPOINT_URL      [core]¶  allowed_deserialization_classes¶  New in version 2.5.0.  What classes can be imported during deserialization. This is a multi line value. The individual items will be parsed as regexp. Python built-in classes (like dict) are always allowed. Bare “.” will be replaced so you can set airflow.*.  Type string  Default airflow\\..*  Environment Variable AIRFLOW__CORE__ALLOWED_DESERIALIZATION_CLASSES     check_slas¶  New in version 1.10.8.  On each dagrun check against defined SLAs  Type string  Default True  Environment Variable AIRFLOW__CORE__CHECK_SLAS     compress_serialized_dags¶  New in version 2.3.0.  If True, serialized DAGs are compressed before writing to DB. Note: this will disable the DAG dependencies view  Type string  Default False  Environment Variable AIRFLOW__CORE__COMPRESS_SERIALIZED_DAGS     daemon_umask¶  New in version 2.3.4.\n",
      ">>>\n",
      "Extracted relevant parts:\n",
      ">>>\n",
      "Default http://localhost:8080  Environment Variable AIRFLOW__CLI__ENDPOINT_URL      [core]¶  allowed_deserialization_classes¶  New in version 2.5.0.  What classes can be imported during deserialization. This is a multi line value. The individual items will be parsed as regexp. Python built-in classes (like dict) are always allowed. Bare “.” will be replaced so you can set airflow.*.  Type string  Default airflow\\..*  Environment Variable AIRFLOW__CORE__ALLOWED_DESERIALIZATION_CLASSES     check_slas¶  New in version 1.10.8.  On each dagrun check against defined SLAs  Type string  Default True  Environment Variable AIRFLOW__CORE__CHECK_SLAS     compress_serialized_dags¶  New in version 2.3.0.  If True, serialized DAGs are compressed before writing to DB. Note: this will disable the DAG dependencies view  Type string  Default False  Environment Variable AIRFLOW__CORE__COMPRESS_SERIALIZED_DAGS     daemon_umask¶  New in version 2.3.4.\n",
      ">>>\n",
      "Extracted relevant parts:\n",
      ">>>\n",
      "Default http://localhost:8080  Environment Variable AIRFLOW__CLI__ENDPOINT_URL      [core]¶  allowed_deserialization_classes¶  New in version 2.5.0.  What classes can be imported during deserialization. This is a multi line value. The individual items will be parsed as regexp. Python built-in classes (like dict) are always allowed. Bare “.” will be replaced so you can set airflow.*.  Type string  Default airflow\\..*  Environment Variable AIRFLOW__CORE__ALLOWED_DESERIALIZATION_CLASSES     check_slas¶  New in version 1.10.8.  On each dagrun check against defined SLAs  Type string  Default True  Environment Variable AIRFLOW__CORE__CHECK_SLAS     compress_serialized_dags¶  New in version 2.3.0.  If True, serialized DAGs are compressed before writing to DB. Note: this will disable the DAG dependencies view  Type string  Default False  Environment Variable AIRFLOW__CORE__COMPRESS_SERIALIZED_DAGS     daemon_umask¶\n",
      "\n",
      ">>>\n",
      "current: def __init__(     dag_folder=None,     include_examples=conf.getboolean(\"core\", \"LOAD_EXAMPLES\"),     safe_mode=conf.getboolean(\"core\", \"DAG_DISCOVERY_SAFE_MODE\"),     read_dags_from_db=False, ):    ...   If you were using positional arguments, it requires no change but if you were using keyword arguments, please change store_serialized_dags to read_dags_from_db. Similarly, if you were using DagBag().store_serialized_dags property, change it to DagBag().read_dags_from_db.\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      ">>>\n",
      "\n",
      ">>>\n",
      "The following parameters are relevant for your configuration:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n",
      ">>>\n",
      "Scheduler:\n"
     ]
    }
   ],
   "source": [
    "question = \"Python Code to create a Dag Class\"\n",
    "docs = compression_retriever.get_relevant_documents(question)\n",
    "result_text = \"\\n\\n\".join([doc.page_content for doc in docs])\n",
    "print(result_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8d6db4-19fe-4964-86ff-b7571dc83777",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
